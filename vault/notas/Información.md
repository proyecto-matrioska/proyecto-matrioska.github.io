---
date: 2023-09-28
title: Información
---

# Información

Actualizado: {{ date | date: '%Y-%m-%d' }} { .post-date }

Consideramos dos enfoques de la información. El enfoque clásico, matemático y formal de Shannon, y el enfoque fenomenológico de este proyecto.

## Información, lenguaje, probabilidad y entropía

Como una teoría lógico-matemática la información está ligada a los conceptos de probabilidad y entropía. Más aún, la información depende en su totalidad de la existencia de un lenguaje.

Desde esta perspectiva la información es un valor, una medida. La **cantidad de información** que existe en dentro de un sistema cerrado es función del lenguaje con el que se codifica dicho sistema. El valor mide qué tan probable es que los mensajes codificados que hay en ese sistema existan ahí de entre todos los posibles mensajes que dicho lenguaje permite. A menor probabilidad de ocurrir, mayor será la cantidad de información que nos dará recibir un determinado mensaje.

Como tal, la información en este enfoque tiene varios supuestos:

- Es una teoría lingüística.
- Como medida es dependiente del lenguaje que la codifica.
- No sólo asume lenguaje, asume códigos, el primer estudio de una teoría matemática de la información es el estudio de la codificación.

Al ser una teoría lingüistica, formal, y una medida probabilística, la información también está relacionada con el concepto de entropía. Por una parte, la información no sólo se codifica en abstracto, sino que implementamos dichas codificaciones en sistemas de señales electromagnéticas.

Una información codificada como tal es entonces un arreglo de partículas subatómicas, como electrones, por ejemplo. Este arreglo pareciera ser totalmente artificial, es decir, es casi improbable que surja sin intervención humana en la naturaleza. 

De acuerdo con [[notas/Vilém Flusser|Vilém Flusser]], esto nos pone a contrapelo con la entropía. Nuestros modelos físicos del Univeso, en particular las teorías termodinámicas, predicen una explosión total de la entropía, mientras que los seres humanos, con nuestras computadoras, caminamos en el sentido totalmente contrario.

Debemos tener cuidado con estas interpretaciones, pues hay que recordar que la información de Shannon mide cuánta información hay, no da ninguna referencia a sus contenidos. Por lo tanto, las predicciones de la termodinámica no dictan la desaparición de la información, sino su estabilidad.

## Información, abstracción, dialéctica y sentido

En este nuevo enfoque, caracterizamos a la información y su procesamiento como un fenómeno de abstracción y significación del mundo.

tags:: [[notas/Claude Shannon|Claude Shannon]], [[notas/Vilém Flusser|Vilém Flusser]]
